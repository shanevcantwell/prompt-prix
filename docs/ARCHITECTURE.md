# Architecture

This document describes the system architecture of prompt-prix, including module responsibilities, data flow, and key design decisions.

## System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           Browser                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    Gradio UI (ui.py)                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Config Panel‚îÇ ‚îÇ Prompt Input ‚îÇ ‚îÇ Model Output Tabs     ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Servers   ‚îÇ ‚îÇ ‚Ä¢ Single     ‚îÇ ‚îÇ ‚Ä¢ Tab 1..10           ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Models    ‚îÇ ‚îÇ ‚Ä¢ Batch      ‚îÇ ‚îÇ ‚Ä¢ Streaming display   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ System    ‚îÇ ‚îÇ ‚Ä¢ Tools JSON ‚îÇ ‚îÇ ‚Ä¢ Status colors       ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Prompt    ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ localStorage: servers, models, temperature, etc.        ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Python Backend                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    handlers.py (Orchestration)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ fetch_available_models()  ‚Üí adapter.get_available_models() ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ initialize_session()      ‚Üí Create ComparisonSession       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ send_single_prompt()      ‚Üí adapter.stream_completion()    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ export_markdown/json()    ‚Üí Report generation              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                ‚îÇ                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              adapters/ (Resource Management)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                             ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  LMStudioAdapter                                         ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ _pool: ServerPool (internal)                          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ stream_completion() ‚Üí finds server, streams, releases ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ get_available_models() ‚Üí queries all servers          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Future: HFInferenceAdapter, SurfMcpAdapter                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                ‚îÇ                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    config.py                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Pydantic Models: ServerConfig, ModelContext, SessionState   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Constants: DEFAULT_TEMPERATURE, DEFAULT_MAX_TOKENS, etc.    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Environment: load_servers_from_env(), get_gradio_port()     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    LM Studio Servers                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  Server 1 (e.g. 3090)  ‚îÇ    ‚îÇ  Server 2 (e.g. 8000)  ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GET /v1/models      ‚îÇ    ‚îÇ  ‚Ä¢ GET /v1/models      ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ POST /v1/chat/...   ‚îÇ    ‚îÇ  ‚Ä¢ POST /v1/chat/...   ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Model A            ‚îÇ    ‚îÇ  ‚îî‚îÄ Model B, C         ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Model B            ‚îÇ    ‚îÇ                        ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Layer Import Rules

Per [ADR-006](adr/006-adapter-resource-ownership.md), the codebase has strict layer boundaries:

| Layer | MAY Import | MUST NOT Import |
|-------|------------|-----------------|
| **Orchestration** (BatteryRunner, ConsistencyRunner, ComparisonSession) | `react.dispatch`, `mcp.tools.*`, `mcp.registry` | `adapters/*`, ServerPool, ConcurrentDispatcher |
| **Dispatch** (`react/dispatch.py`) | `mcp.tools.*`, `react.schemas`, `react.cycle_detection` | `adapters/*`, orchestration |
| **MCP Primitives** | `adapters.base.HostAdapter` (protocol), `mcp.registry` | Concrete adapter classes, ServerPool |
| **Adapters** | httpx, internal utilities | Nothing from orchestration or MCP |

> **THE RULE:** ServerPool and ConcurrentDispatcher are INTERNAL to LMStudioAdapter.
> No file outside `adapters/lmstudio.py` may import or reference them.

## Module Breakdown

### Directory Structure

```
prompt_prix/
‚îú‚îÄ‚îÄ main.py              # Entry point, adapter registration
‚îú‚îÄ‚îÄ ui.py                # Gradio UI definition
‚îú‚îÄ‚îÄ handlers.py          # Shared event handlers (fetch, stop)
‚îú‚îÄ‚îÄ state.py             # Global mutable state
‚îú‚îÄ‚îÄ core.py              # ComparisonSession (orchestration)
‚îú‚îÄ‚îÄ config.py            # Pydantic models, constants, env loading
‚îú‚îÄ‚îÄ parsers.py           # Input parsing utilities
‚îú‚îÄ‚îÄ export.py            # Report generation
‚îú‚îÄ‚îÄ battery.py           # BatteryRunner (orchestration) - calls execute_test_case()
‚îú‚îÄ‚îÄ consistency.py       # ConsistencyRunner - multi-run variance testing
‚îú‚îÄ‚îÄ react/               # ReAct loop execution
‚îÇ   ‚îú‚îÄ‚îÄ dispatch.py      # execute_test_case() ‚Äî single dispatch (ONLY mode reader)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py       # ReActIteration, ToolCall data models
‚îÇ   ‚îî‚îÄ‚îÄ cycle_detection.py # Stagnation / cycle detection
‚îú‚îÄ‚îÄ mcp/
‚îÇ   ‚îú‚îÄ‚îÄ registry.py      # Adapter registry (get_adapter, register_adapter)
‚îÇ   ‚îî‚îÄ‚îÄ tools/
‚îÇ       ‚îú‚îÄ‚îÄ complete.py  # complete, complete_stream, latency sentinel utilities
‚îÇ       ‚îú‚îÄ‚îÄ react_step.py # Stateless single ReAct iteration primitive
‚îÇ       ‚îú‚îÄ‚îÄ drift.py     # Embedding-based semantic drift calculation
‚îÇ       ‚îú‚îÄ‚îÄ judge.py     # LLM-as-judge evaluation
‚îÇ       ‚îî‚îÄ‚îÄ list_models.py
‚îú‚îÄ‚îÄ tabs/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ battery/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ handlers.py  # Battery-specific handlers
‚îÇ   ‚îî‚îÄ‚îÄ compare/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ handlers.py  # Compare-specific handlers
‚îú‚îÄ‚îÄ adapters/
‚îÇ   ‚îú‚îÄ‚îÄ base.py          # HostAdapter protocol
‚îÇ   ‚îî‚îÄ‚îÄ lmstudio.py      # LMStudioAdapter (OWNS ServerPool, ConcurrentDispatcher)
‚îú‚îÄ‚îÄ semantic_validator.py # Response validation (refusals, tool calls, verdicts)
‚îî‚îÄ‚îÄ benchmarks/
    ‚îú‚îÄ‚îÄ base.py          # BenchmarkCase dataclass
    ‚îú‚îÄ‚îÄ custom_json.py   # CustomJSONLoader (JSON/JSONL)
    ‚îî‚îÄ‚îÄ promptfoo.py     # PromptfooLoader (YAML format)
```

### config.py - Configuration & Data Models

**Purpose**: Define all Pydantic models for type-safe configuration and state.

| Class | Purpose |
|-------|---------|
| `ServerConfig` | Single LM Studio server state (URL, available_models, is_busy) |
| `ModelConfig` | Model identity and display name |
| `Message` | Single message in a conversation (role, content - supports multimodal) |
| `ModelContext` | Complete conversation history for one model |
| `SessionState` | Full session: models, contexts, system_prompt, halted status |

**Message Multimodal Support**:
The `Message` model supports both text and multimodal content:
```python
# Text-only message
Message(role="user", content="Hello")

# Multimodal message (text + image)
Message(role="user", content=[
    {"type": "text", "text": "What's in this image?"},
    {"type": "image_url", "image_url": {"url": "data:image/png;base64,..."}}
])

# Helper methods
msg.get_text()   # Extract text content
msg.has_image()  # Check if message contains an image
```

**Key Functions**:
- `load_servers_from_env()` - Read LM_STUDIO_SERVER_N environment variables
- `get_default_servers()` - Return env servers or placeholder defaults
- `get_gradio_port()` - Read GRADIO_PORT or default to 7860
- `encode_image_to_data_url(path)` - Convert image file to base64 data URL
- `build_multimodal_content(text, image_path)` - Build OpenAI-format multimodal content

### core.py - Session Management (Orchestration Layer)

**Purpose**: Orchestration-level session management.

#### ComparisonSession

Manages a comparison session. Calls MCP tools, not adapters directly.

```python
class ComparisonSession:
    state: SessionState  # Contains models, contexts, config

    async def send_prompt_to_model(model_id, prompt, on_chunk=None)
    async def send_prompt_to_all(prompt, on_chunk=None)
    def get_context_display(model_id) -> str
```

### handlers.py - Shared Event Handlers

**Purpose**: Shared async handlers used across multiple tabs.

| Handler | Purpose | Returns |
|---------|---------|---------|
| `fetch_available_models(servers_text)` | Query all servers for available models | `(status, gr.update(choices=[...]))` |
| `handle_stop()` | Signal cancellation via global state | `status` |
| `_init_pool_and_validate(servers_text, models)` | Initialize ServerPool and validate models | `(pool, error_message)` |

### tabs/battery/handlers.py - Battery Tab Handlers

**Purpose**: Handlers specific to the Battery (benchmark) tab.

| Handler | Trigger | Returns |
|---------|---------|---------|
| `validate_file(file_path)` | File upload | Validation status string |
| `get_test_ids(file_path)` | File upload | List of test IDs |
| `run_handler(file, models, servers, ...)` | "Run Battery" button | Generator yielding `(status, grid_df)` |
| `quick_prompt_handler(prompt, models, ...)` | "Run Prompt" button | Markdown results |
| `export_json()` | "Export JSON" button | `(status, preview)` |
| `export_csv()` | "Export CSV" button | `(status, preview)` |
| `get_cell_detail(model, test)` | Detail dropdown | Markdown detail |
| `refresh_grid(display_mode)` | Display mode change | Updated grid DataFrame |

### tabs/compare/handlers.py - Compare Tab Handlers

**Purpose**: Handlers specific to the Compare (interactive) tab.

| Handler | Trigger | Returns |
|---------|---------|---------|
| `initialize_session(servers, models, system_prompt, ...)` | Auto-init on send | `(status, *model_tabs)` |
| `send_single_prompt(prompt, tools_json, image_path, seed, repeat_penalty)` | "Send to All" button | Generator yielding `(status, tab_states, *model_outputs)` |
| `export_markdown()` | "Export Markdown" button | `(status, preview)` |
| `export_json()` | "Export JSON" button | `(status, preview)` |
| `launch_beyond_compare(model_a, model_b)` | "Open in Beyond Compare" button | `status` |

**Compare Tab Features**:
- **Image Attachment**: Upload images for vision models (encoded as base64 data URLs)
- **Seed Parameter**: Set a seed for reproducible outputs across models
- **Repeat Penalty**: Configurable penalty (1.0-2.0) to reduce repetitive token generation

### ui.py - Gradio UI Definition

**Purpose**: Define all Gradio components and wire up event bindings.

**Key Components**:

| Component | Type | Purpose |
|-----------|------|---------|
| `servers_input` | Textbox | LM Studio server URLs (one per line) |
| `models_checkboxes` | CheckboxGroup | Select models to compare |
| `system_prompt_input` | Textbox (50 lines) | Editable system prompt |
| `temperature_slider` | Slider | Model temperature (0-2) |
| `timeout_slider` | Slider | Request timeout (30-600s) |
| `max_tokens_slider` | Slider | Max tokens (256-8192) |
| `seed_input` | Number | Optional seed for reproducible outputs |
| `repeat_penalty_slider` | Slider | Repeat penalty (1.0-2.0, default 1.1) |
| `prompt_input` | Textbox | User prompt entry |
| `image_input` | Image | Optional image attachment for vision models |
| `tools_input` | Code (JSON) | Tools for function calling |
| `model_outputs[0..9]` | Markdown | Model response tabs |
| `tab_states` | JSON (hidden) | Tab status for color updates |

**Event Bindings**:
- Buttons trigger async handlers
- `tab_states.change` triggers JavaScript for inline style updates
- `app.load` restores state from localStorage

### state.py - Global State

**Purpose**: Holds mutable state shared across handlers.

```python
session: Optional[ComparisonSession] = None
```

**Design Decision**: Separated to avoid circular imports between ui.py and handlers.py.

### adapters/ - Inference Provider Adapters

**Purpose**: Encapsulate backend-specific logic behind a uniform interface.

Per [ADR-006](adr/006-adapter-resource-ownership.md), the architecture has three strict layers:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        ORCHESTRATION                            ‚îÇ
‚îÇ  BatteryRunner ‚îÇ ConsistencyRunner ‚îÇ ComparisonSession          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Zero mode awareness ‚Äî doesn't know react from single-shot   ‚îÇ
‚îÇ  ‚Ä¢ Calls execute_test_case(), receives CaseResult              ‚îÇ
‚îÇ  ‚Ä¢ Controls concurrency, validation pipeline (refusal ‚Üí drift) ‚îÇ
‚îÇ  ‚Ä¢ NEVER IMPORTS: adapters/*, ServerPool, ConcurrentDispatcher  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ execute_test_case(test, model_id, ...)
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     DISPATCH (react/dispatch.py)                ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  execute_test_case() ‚Äî the ONLY place that reads test.mode      ‚îÇ
‚îÇ    mode=None    ‚Üí _execute_single_shot() ‚Üí complete_stream()    ‚îÇ
‚îÇ    mode="react" ‚Üí _execute_react() ‚Üí react_step() √ó N          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Returns CaseResult(response, latency_ms, react_trace)          ‚îÇ
‚îÇ  Raises ReactLoopIncomplete on cycle / max_iterations           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ MCP tool call
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       MCP PRIMITIVES                            ‚îÇ
‚îÇ  complete_stream ‚îÇ react_step ‚îÇ judge ‚îÇ drift ‚îÇ list_models     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Receives adapter via registry (get_adapter())                ‚îÇ
‚îÇ  ‚Ä¢ Stateless ‚Äî no mode awareness                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ adapter.stream_completion()
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       ADAPTER LAYER                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  LMStudioAdapter                                                ‚îÇ
‚îÇ    INTERNAL: ServerPool, ConcurrentDispatcher, httpx            ‚îÇ
‚îÇ    STRATEGY: Multi-GPU parallel dispatch                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  HFInferenceAdapter                                             ‚îÇ
‚îÇ    INTERNAL: API client, rate limiter                           ‚îÇ
‚îÇ    STRATEGY: Rate-limited cloud calls                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### HostAdapter Protocol

```python
class HostAdapter(Protocol):
    async def get_available_models(self) -> list[str]: ...
    async def stream_completion(
        self,
        model_id: str,
        messages: list[dict],
        temperature: float,
        max_tokens: int,
        timeout_seconds: int,
        tools: Optional[list[dict]] = None
    ) -> AsyncGenerator[str, None]: ...
```

#### LMStudioAdapter

```python
class LMStudioAdapter:
    def __init__(self, server_urls: list[str]):
        # ServerPool and ConcurrentDispatcher are INTERNAL
        self._pool = ServerPool(server_urls)
        self._dispatcher = ConcurrentDispatcher(self._pool)

    async def stream_completion(...) -> AsyncGenerator[str, None]:
        # Finds available server, acquires it, streams, releases
```

**Key Principle**: ServerPool and ConcurrentDispatcher are LM Studio concepts. Other backends have different resource models. The adapter encapsulates this ‚Äî orchestration never sees these classes.

### parsers.py - Text Parsing Utilities

**Purpose**: Parse user input from UI components.

| Function | Input | Output |
|----------|-------|--------|
| `parse_models_input(text)` | "model1\nmodel2" | `["model1", "model2"]` |
| `parse_servers_input(text)` | "http://...\nhttp://..." | `["http://...", "http://..."]` |
| `parse_prompts_file(content)` | File content | List of prompts |
| `load_system_prompt(file_path)` | Optional file path | System prompt string |
| `get_default_system_prompt()` | - | Default prompt from file or constant |

### export.py - Report Generation

**Purpose**: Generate exportable reports from session state.

```python
def generate_markdown_report(state: SessionState) -> str:
    """Create Markdown with header, system prompt, and all model conversations."""

def generate_json_report(state: SessionState) -> str:
    """Create structured JSON with configuration and conversations."""

def save_report(content: str, filepath: str):
    """Write report to file."""
```

### main.py - Entry Point

**Purpose**: Application entry point and backwards-compatibility exports.

```python
def run():
    app = create_app()
    app.launch(server_name="0.0.0.0", server_port=get_gradio_port())
```

## Data Flow: Sending a Prompt

```
1. User types prompt, clicks "Send Prompt"
         ‚îÇ
         ‚ñº
2. ui.py: send_button.click(fn=send_single_prompt, inputs=[prompt, tools])
         ‚îÇ
         ‚ñº
3. handlers.py: send_single_prompt(prompt, tools_json)
   ‚îÇ - Validate session exists
   ‚îÇ - Parse tools JSON
   ‚îÇ - Add user message to all model contexts
   ‚îÇ - Refresh server manifests
         ‚îÇ
         ‚ñº
4. Concurrent Dispatcher Loop:
   ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ ‚îÇ For each idle server:                   ‚îÇ
   ‚îÇ ‚îÇ   Find model in queue this server has   ‚îÇ
   ‚îÇ ‚îÇ   If found: start async task            ‚îÇ
   ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ ‚îÇ await asyncio.sleep(0.1)
   ‚îÇ ‚îÇ yield (status, tab_states, *outputs)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ UI updates
   ‚îÇ ‚îÇ Clean up completed tasks
   ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ while queue or active_tasks
         ‚îÇ
         ‚ñº
5. Each async task: run_model_on_server(model_id, server_url)
   ‚îÇ - Mark model as "streaming"
   ‚îÇ - Call stream_completion() ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ LM Studio API
   ‚îÇ - Accumulate chunks in streaming_responses[model_id]
   ‚îÇ - On complete: add assistant message to context
   ‚îÇ - Release server
         ‚îÇ
         ‚ñº
6. Final yield: ("‚úÖ All responses complete", final_states, *final_outputs)
```

## State Management

### Session State (Python)

```python
SessionState:
  models: list[str]                    # Selected models
  contexts: dict[str, ModelContext]    # model_id -> conversation
  system_prompt: str
  temperature: float
  timeout_seconds: int
  max_tokens: int
  halted: bool                         # True if any model failed
  halt_reason: Optional[str]
```

### UI State (Browser localStorage)

| Key | Type | Purpose |
|-----|------|---------|
| `promptprix_servers` | string | Server URLs (newline-separated) |
| `promptprix_model_choices` | JSON array | Available models from last fetch |
| `promptprix_models` | JSON array | Selected models |
| `promptprix_temperature` | float | Temperature setting |
| `promptprix_timeout` | int | Timeout setting |
| `promptprix_max_tokens` | int | Max tokens setting |
| `promptprix_tools` | string | Tools JSON |
| `promptprix_system_prompt` | string | System prompt text |

**Persistence**: Only saved when user clicks "Save State" button (explicit save).

## Tab Status Visualization

Tab colors indicate model status during streaming:

| Status | Color | Border |
|--------|-------|--------|
| `pending` | Red gradient (#fee2e2 ‚Üí #fecaca) | 4px solid #ef4444 |
| `streaming` | Yellow gradient (#fef3c7 ‚Üí #fde68a) | 4px solid #f59e0b |
| `completed` | Green gradient (#d1fae5 ‚Üí #a7f3d0) | 4px solid #10b981 |

**Implementation**: Uses inline JavaScript styles (`element.style`) to overcome Gradio theme CSS.

## Error Handling

### Fail-Fast Validation

1. `initialize_session` validates:
   - Servers are configured
   - Models are configured
   - All selected models exist on at least one server

2. `send_single_prompt` validates:
   - Session is initialized
   - Session is not halted
   - Prompt is not empty
   - Tools JSON is valid (if provided)

### Halt-on-Error

If any model fails during `send_prompt_to_all`:
- `state.halted = True`
- `state.halt_reason = "Model {model_id} failed: {error}"`
- Subsequent prompts are rejected

### Human-Readable Errors

The `LMStudioError` exception extracts error messages from LM Studio's JSON responses:

```python
{"error": {"message": "Model not loaded"}}  ‚Üí  "Model not loaded"
```

## Integration Points

### Upstream: Benchmark Sources

prompt-prix can consume test cases from established benchmark ecosystems:

| Source | Format | Usage |
|--------|--------|-------|
| **BFCL** | JSON with function schemas | Export test cases, load in batch mode |
| **Inspect AI** | Python test definitions | Export prompts, import as JSON |
| **Custom JSON** | OpenAI-compatible messages | Direct load in prompt-prix |

See [ADR-001](adr/001-use-existing-benchmarks.md) for rationale.

### API Layer: OpenAI-Compatible

All inference servers must expose OpenAI-compatible endpoints:

```
GET  /v1/models              ‚Üí List available models
POST /v1/chat/completions    ‚Üí Chat completion (streaming)
```

Supported servers:
- LM Studio (native)
- Ollama (OpenAI mode)
- vLLM
- llama.cpp server
- Any OpenAI-compatible proxy

See [ADR-003](adr/003-openai-compatible-api.md) for rationale.

## Battery File Formats

The Battery tab accepts test files in multiple formats:

### JSON / JSONL

```json
{
  "prompts": [
    {"id": "test-1", "user": "What is 2+2?", "expected": "4"},
    {"id": "test-2", "user": "Call get_weather", "tools": [...], "tool_choice": "required"}
  ]
}
```

**Required fields**: `id`, `user`

**Optional fields**: `name`, `category`, `severity`, `system`, `tools`, `tool_choice`, `expected`, `pass_criteria`, `fail_criteria`, `expected_response`

### Promptfoo YAML

[Promptfoo](https://promptfoo.dev) config files are supported with variable substitution:

```yaml
prompts:
  - |
    {{system}}
    User: {{user}}

tests:
  - description: "Clear Pass - Exact Match"
    vars:
      system: "You are evaluating tool call outputs..."
      user: "Evaluate this output..."
      expected_verdict: PASS                    # ‚Üí pass_criteria (for LLM judge)
      expected_response: "The answer is 4"      # ‚Üí expected_response (for drift)
      category: clear_discrimination
    assert:
      - type: javascript                        # Logged but NOT evaluated
        value: "result.verdict === 'PASS'"
```

**Promptfoo vars extraction**:

| Var | BenchmarkCase field | Purpose |
|-----|-------------------|---------|
| `expected_verdict` | `pass_criteria` | Rubric text for LLM judge evaluation |
| `expected_response` | `expected_response` | Exemplar text for embedding drift comparison |
| `category` | `category` | Test category for filtering/grouping |
| `system` | `system` | System message |
| `user` | `user` | User message |

- `assert` blocks ‚Üí **Logged but NOT evaluated** (warning emitted)

See `prompt_prix/benchmarks/promptfoo.py` for implementation.

## Semantic Validation

Battery tests validate responses beyond HTTP success. The semantic validator (`prompt_prix/semantic_validator.py`) checks:

### Validation Types

| Check | Trigger | Failure Reason |
|-------|---------|----------------|
| **Empty response** | Response is empty/whitespace | "Empty response" |
| **Refusal detection** | Matches refusal phrases | "Model refused: '{phrase}'" |
| **Tool call required** | `tool_choice: "required"` | "Expected tool call but got text response" |
| **Tool call forbidden** | `tool_choice: "none"` | "Tool call made when tool_choice='none'" |
| **Verdict matching** | `pass_criteria` contains verdict | "Verdict mismatch: expected X, got Y" |

### Verdict Matching (Judge Competence Tests)

When `pass_criteria` contains "verdict must be", the validator extracts the verdict from JSON in the response and compares it:

```python
# pass_criteria: "The verdict in the JSON response must be 'FAIL'"
# Response: {"verdict": "PASS", "score": 1.0, "reasoning": "..."}
# Result: SEMANTIC_FAILURE - "Verdict mismatch: expected FAIL, got PASS"
```

This enables testing whether a model can correctly judge other outputs (judge competence tests).

### Test Status Values

| Status | Symbol | Meaning |
|--------|--------|---------|
| `COMPLETED` | ‚úì | Response passed semantic validation |
| `SEMANTIC_FAILURE` | ‚ùå | Response received but failed semantic check |
| `ERROR` | ‚ö† | Infrastructure error (timeout, connection, etc.) |

### Validation Order

Checks run in order (first failure wins):
1. Empty response check
2. Refusal detection
3. Tool call validation (if `tool_choice` set)
4. Verdict matching (if `pass_criteria` specifies verdict)

## Fan-Out Dispatcher Pattern

The core abstraction is **fan-out**: one prompt dispatched to N models in parallel.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Fan-Out Dispatcher                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Input: (prompt, [model_a, model_b, model_c])               ‚îÇ
‚îÇ                        ‚îÇ                                     ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ         ‚ñº              ‚ñº              ‚ñº                     ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ    ‚îÇ Model A ‚îÇ    ‚îÇ Model B ‚îÇ    ‚îÇ Model C ‚îÇ               ‚îÇ
‚îÇ    ‚îÇ Server1 ‚îÇ    ‚îÇ Server1 ‚îÇ    ‚îÇ Server2 ‚îÇ               ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ         ‚îÇ              ‚îÇ              ‚îÇ                     ‚îÇ
‚îÇ         ‚ñº              ‚ñº              ‚ñº                     ‚îÇ
‚îÇ    Response A     Response B     Response C                 ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Output: {model_a: resp_a, model_b: resp_b, model_c: resp_c}‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Parallel Dispatch

The dispatcher maximizes GPU utilization:

1. **Queue**: All work items (model + test pairs)
2. **Match**: Find idle server that has the required model loaded
3. **Execute**: Stream response, update UI
4. **Release**: Server becomes available for next item

This keeps all GPUs busy even when models are distributed across servers.

See [ADR-002](adr/002-fan-out-pattern-as-core.md) for rationale.

## Battery Execution: Pipelined Judging

When a judge model is selected, BatteryRunner uses **pipelined execution** ‚Äî judge tasks are submitted eagerly as inference results complete, rather than waiting for all inference to finish first.

```
Without pipelining (original two-phase, ADR-008):
  Phase 1: [inference][inference][inference][inference]
  Phase 2:                                              [judge][judge][judge][judge]

With pipelining:
  GPU0:    [inference][inference][judge][judge][judge]    ‚Üê GPU0 idles early, starts judging
  GPU1:    [inference][inference][inference][inference]   ‚Üê GPU1 still doing heavy models
```

The `current_model` drain guard on `ServerPool` is the enabler ‚Äî judge tasks queue in the dispatcher until a server drains its inference model. No priority queues or server affinity needed.

Key methods in `battery.py`:
- `_execute_pipelined()` ‚Äî tracks `inference_tasks` and `judge_tasks` in separate sets
- `_inference_then_judge()` ‚Äî wraps `_execute_test()`, submits judge task on success
- `_execute_inference_phase()` ‚Äî used when no judge model (zero overhead)

When no judge model is set, `_execute_inference_phase()` runs directly with no pipelining overhead.

See [ADR-008](adr/ADR-008-judge-scheduling-strategy.md) for the evolution from two-phase to pipelined scheduling.

## ReAct Loop Execution

Tests can specify `mode="react"` to evaluate multi-step tool-use loops. The key design decision: **a react loop is just another way to produce a pass/fail verdict for a (test, model) cell.** React tests flow through the same `BatteryRunner`/`ConsistencyRunner` pipeline as standard tests ‚Äî they get drift validation, judge evaluation, and consistency testing for free.

### Dispatch Layer

`react/dispatch.py` contains `execute_test_case()`, the **single dispatch function** and the ONLY place that reads `test.mode`:

```python
async def execute_test_case(test, model_id, ...) -> CaseResult:
    if test.mode == "react":
        return await _execute_react(...)    # react_step() √ó N
    else:
        return await _execute_single_shot(...)  # complete_stream()
```

Orchestration above has zero mode awareness. MCP tools below have zero mode awareness.

### CaseResult ‚Üí RunResult Flow

| `CaseResult` field | `RunResult` field | Notes |
|-------------------|-------------------|-------|
| `response` | `response` | Final text answer (model output or react loop conclusion) |
| `latency_ms` | `latency_ms` | Total inference time (summed across all steps for react) |
| `react_trace` | `react_trace` | `None` for single-shot; dict with iteration detail for react |

### React Loop Mechanics

The react loop in `_execute_react()`:
1. Calls `react_step()` MCP primitive (stateless ‚Äî takes trace in, returns one step out)
2. Accumulates `ReActIteration` objects in the trace
3. Checks for stagnation via `detect_cycle_with_pattern()` after each step
4. If the model responds with text only (no tool calls), the loop completes
5. If `max_iterations` is exhausted or a cycle is detected, raises `ReactLoopIncomplete`

### Error Handling

| Outcome | Result |
|---------|--------|
| Loop completes (model gives final text answer) | `CaseResult` with `react_trace` ‚Üí `RunResult(COMPLETED)` |
| Cycle detected (model repeats tool call pattern) | `ReactLoopIncomplete` ‚Üí `RunResult(SEMANTIC_FAILURE)` |
| Max iterations exhausted | `ReactLoopIncomplete` ‚Üí `RunResult(SEMANTIC_FAILURE)` |
| Infrastructure error (connection, timeout) | Exception propagates ‚Üí `RunResult(ERROR)` |

### Detail View

When a user clicks a react test cell in the battery grid, the detail view renders the `react_trace` dict showing each iteration: tool name, arguments, observation, success/fail status, and latency.

## Consistency Testing

`ConsistencyRunner` (in `consistency.py`) runs each (test, model) cell N times with different random seeds to identify models that produce inconsistent results.

| Status | Symbol | Meaning |
|--------|--------|---------|
| `CONSISTENT_PASS` | ‚úì | N/N runs passed |
| `CONSISTENT_FAIL` | ‚ùå | 0/N runs passed |
| `INCONSISTENT` | üü£ 3/5 | Some runs passed, some failed |
| `PENDING` | ‚è≥ 2/5 | Not all runs complete |

Key types:
- `CellAggregate` ‚Äî aggregated results for one (test, model) cell across N runs
- `ConsistencyRun` ‚Äî state model (like `BatteryRun` but stores aggregates)
- `ConsistencyRunner` ‚Äî orchestrator with same pipelined judging as `BatteryRunner`

See [ADR-010](adr/ADR-010-consistency-runner.md) for rationale.

## Architecture Decision Records

| ADR | Decision |
|-----|----------|
| [001](adr/001-use-existing-benchmarks.md) | Use existing benchmarks (BFCL, Inspect AI) instead of custom eval schema |
| [002](adr/002-fan-out-pattern-as-core.md) | Fan-out pattern as core architectural abstraction |
| [003](adr/003-openai-compatible-api.md) | OpenAI-compatible API as sole integration layer |
| [006](adr/006-adapter-resource-ownership.md) | Adapters own their resource management (ServerPool internal to LMStudioAdapter) |
| [007](adr/ADR-007-inference-task-schema.md) | InferenceTask schema for adapter interface |
| [008](adr/ADR-008-judge-scheduling-strategy.md) | Pipelined judge scheduling for multi-GPU efficiency |
| [009](adr/ADR-009-interactive-battery-grid.md) | Dismissible dialog for battery grid cell detail |
| [010](adr/ADR-010-consistency-runner.md) | Multi-run consistency analysis (proposed) |
| [011](adr/ADR-011-embedding-based-validation.md) | Embedding-based semantic validation (proposed) |
| [012](adr/ADR-012-compare-to-battery-export.md) | Compare to Battery export pipeline (proposed) |
